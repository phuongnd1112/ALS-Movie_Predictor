{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-16T13:28:08.848485Z","iopub.execute_input":"2023-04-16T13:28:08.849017Z","iopub.status.idle":"2023-04-16T13:28:08.881711Z","shell.execute_reply.started":"2023-04-16T13:28:08.848972Z","shell.execute_reply":"2023-04-16T13:28:08.880044Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/movierating/movie_ratings_df.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyspark \n!pip install sklearn","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:28:08.884481Z","iopub.execute_input":"2023-04-16T13:28:08.884900Z","iopub.status.idle":"2023-04-16T13:28:32.900691Z","shell.execute_reply.started":"2023-04-16T13:28:08.884862Z","shell.execute_reply":"2023-04-16T13:28:32.898806Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyspark in /opt/conda/lib/python3.7/site-packages (3.4.0)\nRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.7/site-packages (from pyspark) (0.10.9.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0.post4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport random\nimport os\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.functions import mean, col, split, col, regexp_extract, when, lit\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import QuantileDiscretizer","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:28:32.903247Z","iopub.execute_input":"2023-04-16T13:28:32.903822Z","iopub.status.idle":"2023-04-16T13:28:33.671700Z","shell.execute_reply.started":"2023-04-16T13:28:32.903768Z","shell.execute_reply":"2023-04-16T13:28:33.670215Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"spark = SparkSession.builder.appName(\"movie_recommender\").getOrCreate() ","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:28:33.674545Z","iopub.execute_input":"2023-04-16T13:28:33.674984Z","iopub.status.idle":"2023-04-16T13:28:38.606226Z","shell.execute_reply.started":"2023-04-16T13:28:33.674944Z","shell.execute_reply":"2023-04-16T13:28:38.604687Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n23/04/16 13:28:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n/opt/conda/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"df = spark.read.csv('/kaggle/input/movierating', inferSchema = True, header=True) \n\ndf.limit(3).toPandas() \n#limit will only show schema - toPandas() shows table\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:28:38.608071Z","iopub.execute_input":"2023-04-16T13:28:38.608555Z","iopub.status.idle":"2023-04-16T13:28:46.585371Z","shell.execute_reply.started":"2023-04-16T13:28:38.608512Z","shell.execute_reply":"2023-04-16T13:28:46.583611Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   userId         title  rating\n0     196  Kolya (1996)       3\n1      63  Kolya (1996)       3\n2     226  Kolya (1996)       5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>title</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>Kolya (1996)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>63</td>\n      <td>Kolya (1996)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>226</td>\n      <td>Kolya (1996)</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Examining the features in the data-set","metadata":{}},{"cell_type":"code","source":"df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:28:46.587578Z","iopub.execute_input":"2023-04-16T13:28:46.588081Z","iopub.status.idle":"2023-04-16T13:28:46.599306Z","shell.execute_reply.started":"2023-04-16T13:28:46.588032Z","shell.execute_reply":"2023-04-16T13:28:46.597626Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"root\n |-- userId: integer (nullable = true)\n |-- title: string (nullable = true)\n |-- rating: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Because 'useId' + 'rating' = integer --> we need to convert title (dtype = string) into something more readable by the ML processor.","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.feature import StringIndexer, IndexToString","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:28:46.601315Z","iopub.execute_input":"2023-04-16T13:28:46.601698Z","iopub.status.idle":"2023-04-16T13:28:46.609832Z","shell.execute_reply.started":"2023-04-16T13:28:46.601661Z","shell.execute_reply":"2023-04-16T13:28:46.608567Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"stringIndexer = StringIndexer(inputCol=\"title\", outputCol=\"title_new\") \nmodel = stringIndexer.fit(df) \nindexed = model.transform(df) \nindexed.limit(5).toPandas()","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:30:47.356618Z","iopub.execute_input":"2023-04-16T13:30:47.357080Z","iopub.status.idle":"2023-04-16T13:30:48.228925Z","shell.execute_reply.started":"2023-04-16T13:30:47.357037Z","shell.execute_reply":"2023-04-16T13:30:48.227482Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   userId         title  rating  title_new\n0     196  Kolya (1996)       3      287.0\n1      63  Kolya (1996)       3      287.0\n2     226  Kolya (1996)       5      287.0\n3     154  Kolya (1996)       3      287.0\n4     306  Kolya (1996)       5      287.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>title</th>\n      <th>rating</th>\n      <th>title_new</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>Kolya (1996)</td>\n      <td>3</td>\n      <td>287.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>63</td>\n      <td>Kolya (1996)</td>\n      <td>3</td>\n      <td>287.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>226</td>\n      <td>Kolya (1996)</td>\n      <td>5</td>\n      <td>287.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>154</td>\n      <td>Kolya (1996)</td>\n      <td>3</td>\n      <td>287.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>306</td>\n      <td>Kolya (1996)</td>\n      <td>5</td>\n      <td>287.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#using alternating least squares (ALS) to predict ratings; ALS solves for matrix optimisation\n\ntrain, test = indexed.randomSplit([0.75, 0.25])\nfrom pyspark.ml.recommendation import ALS \n\nrec = ALS (maxIter = 10, \n          regParam = 0.01, \n          userCol ='userId', \n          ratingCol = 'rating', \n          itemCol = 'title_new', \n          nonnegative = True,\n          coldStartStrategy = \"drop\") #we define the ALS process. \n\nrec_model = rec.fit(train) \n\npredicted_model = rec_model.transform(test) \npredicted_model.limit(5).toPandas() ","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:39:47.742142Z","iopub.execute_input":"2023-04-16T13:39:47.743334Z","iopub.status.idle":"2023-04-16T13:40:01.236677Z","shell.execute_reply.started":"2023-04-16T13:39:47.743266Z","shell.execute_reply":"2023-04-16T13:40:01.235471Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"23/04/16 13:39:52 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n                                                                                \r","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   userId                               title  rating  title_new  prediction\n0     148  Around the World in 80 Days (1956)       4      540.0    1.958437\n1     148         Beauty and the Beast (1991)       4      114.0    3.639122\n2     148                  Being There (1979)       5      290.0    3.557612\n3     148                   Cinderella (1950)       3      243.0    3.276735\n4     148                     Fantasia (1940)       5      153.0    4.773097","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>title</th>\n      <th>rating</th>\n      <th>title_new</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>148</td>\n      <td>Around the World in 80 Days (1956)</td>\n      <td>4</td>\n      <td>540.0</td>\n      <td>1.958437</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>148</td>\n      <td>Beauty and the Beast (1991)</td>\n      <td>4</td>\n      <td>114.0</td>\n      <td>3.639122</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>148</td>\n      <td>Being There (1979)</td>\n      <td>5</td>\n      <td>290.0</td>\n      <td>3.557612</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>148</td>\n      <td>Cinderella (1950)</td>\n      <td>3</td>\n      <td>243.0</td>\n      <td>3.276735</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>148</td>\n      <td>Fantasia (1940)</td>\n      <td>5</td>\n      <td>153.0</td>\n      <td>4.773097</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluating Trained Model","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.evaluation import RegressionEvaluator","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:42:35.172084Z","iopub.execute_input":"2023-04-16T13:42:35.174003Z","iopub.status.idle":"2023-04-16T13:42:35.180593Z","shell.execute_reply.started":"2023-04-16T13:42:35.173928Z","shell.execute_reply":"2023-04-16T13:42:35.178934Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"evaluator = RegressionEvaluator(predictionCol='prediction',\n                               labelCol='rating',\n                              metricName = \"rmse\") \n\n#regression evaluator caluclates RMSE (root mean-squared error - fitted line) - what is a good score? \nrmse = evaluator.evaluate(predicted_model) \nprint(rmse)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T13:45:03.715809Z","iopub.execute_input":"2023-04-16T13:45:03.716631Z","iopub.status.idle":"2023-04-16T13:45:05.750588Z","shell.execute_reply.started":"2023-04-16T13:45:03.716564Z","shell.execute_reply":"2023-04-16T13:45:05.749036Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"1.0294612729134853\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Predicting what User Might Like","metadata":{}},{"cell_type":"markdown","source":"Creating the function Top_movies to recommend userId with movie rated by model. ","metadata":{}},{"cell_type":"code","source":"# all unique movies in dataset\nunique_movies = indexed.select('title_new').distinct() \n#unique_movies.limit(5).toPandas()\n\ndef top_movies(user_id, n): \n    a = unique_movies.alias('a') #alias unique names\n    \n    watched_movies = indexed.filter(indexed['userId'] == user_id).select(\"title_new\") #select user\n    b = watched_movies.alias('b')\n    \n    total_movies = a.join(b, a.title_new == b.title_new, how='left') #comparative point\n    \n    #new df to show unwatched movies for all user\n    unwatched_movies = (total_movies.where(col(\"b.title_new\").isNull()).select(a.title_new).distinct()) \n    \n    #matching selected userId to new df index\n    unwatched_movies = unwatched_movies.withColumn(\"userId\", lit(int(user_id)))\n    \n    #use model to find rec, order by descending and selecting only n entries\n    recommendations = (\n        rec_model.transform(unwatched_movies)\n        .orderBy(\"prediction\", ascending=False)\n        .limit(n)\n    )\n    \n    #converting movie index back to string - creat object + transform\n    movie_title = IndexToString(\n        inputCol=\"title_new\", outputCol=\"title\", labels=model.labels\n    )\n    final_recommendations = movie_title.transform(recommendations)\n\n    # return the recommendations to active user\n    return final_recommendations.show(n, False)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:02:03.486216Z","iopub.execute_input":"2023-04-16T14:02:03.486679Z","iopub.status.idle":"2023-04-16T14:02:03.517231Z","shell.execute_reply.started":"2023-04-16T14:02:03.486643Z","shell.execute_reply":"2023-04-16T14:02:03.515763Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"top_movies(60, 4)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:02:32.505835Z","iopub.execute_input":"2023-04-16T14:02:32.506428Z","iopub.status.idle":"2023-04-16T14:02:34.626085Z","shell.execute_reply.started":"2023-04-16T14:02:32.506380Z","shell.execute_reply":"2023-04-16T14:02:34.624230Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+---------+------+----------+----------------------+\n|title_new|userId|prediction|title                 |\n+---------+------+----------+----------------------+\n|1347.0   |60    |6.6166396 |Angel Baby (1995)     |\n|1411.0   |60    |5.980855  |Boys, Les (1997)      |\n|1277.0   |60    |5.9031873 |Mina Tannenbaum (1994)|\n|1057.0   |60    |5.8961306 |Safe (1995)           |\n+---------+------+----------+----------------------+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}